{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWrDSSi8_nOS"
   },
   "source": [
    "We are using BERT to identify and segregate hate speech comments from across the arrays of comments inside YouTube. for which we are using the google built in methods to fetch the required files and comments taken live from the YouTube, comments are fetched on the network of INDIA to define the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the install files within the notebooks to have them included in every run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (74.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.144.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Downloading google_api_python_client-2.144.0-py2.py3-none-any.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.2 MB 8.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.2 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/12.2 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/12.2 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.2 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/12.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.2 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.1/12.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.5/12.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.5.0 google-api-core-2.19.2 google-api-python-client-2.144.0 google-auth-2.34.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.65.0 httplib2-0.22.0 proto-plus-1.24.0 protobuf-5.28.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pyparsing-3.1.4 rsa-4.9 uritemplate-4.1.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth-oauthlib) (2.34.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.8.30)\n",
      "Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: google-auth-oauthlib\n",
      "Successfully installed google-auth-oauthlib-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install transformers\n",
    "!pip3 install google-api-python-client\n",
    "!pip3 install google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9344,
     "status": "ok",
     "timestamp": 1700550293203,
     "user": {
      "displayName": "5080- Priyanshi Srivastava",
      "userId": "02728519429161914482"
     },
     "user_tz": -330
    },
    "id": "31vo6H0p_Pus",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#All the required libraries and tokens are initialized\n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6HrEGWJBozz"
   },
   "source": [
    "API's and service fetch are taken here a new .json file created on personal google workshop is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBHYiTpbQmVW"
   },
   "source": [
    "Define the necessary variables for YouTube API access, including the scope, API service name, API version, and the path to the client secrets file stored in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700550298726,
     "user": {
      "displayName": "5080- Priyanshi Srivastava",
      "userId": "02728519429161914482"
     },
     "user_tz": -330
    },
    "id": "94MWXWc9iI6-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up YouTube API credentials\n",
    "SCOPES = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "CLIENT_SECRETS_FILE = \"client_secret_422487092710-ud2upt20gb8857oc2mdq5vmsn1jake0c.apps.googleusercontent.com.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DucOb94LB26i"
   },
   "source": [
    "BERT is initialised and token is created to use the sentiment analysis part of the transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhqShkWPQyRu"
   },
   "source": [
    "Load a pre-trained BERT model and tokenizer for sentiment analysis.\n",
    "model_name: This constant defines the name of the hate speech detection model.\n",
    "tokenizer: This object tokenizes the text input.\n",
    "model: This object is used to perform hate speech detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5992,
     "status": "ok",
     "timestamp": 1700550304714,
     "user": {
      "displayName": "5080- Priyanshi Srivastava",
      "userId": "02728519429161914482"
     },
     "user_tz": -330
    },
    "id": "E44xWSfd_eEW",
    "outputId": "a23765fd-f488-4e0c-8d29-1e8a66d51c18",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3582689ba4243e89197916a9f14f701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vishu\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afdff75ef2c4a398cd4490023db28d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35db794748dc45b9be39053180f69d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8cd8b81aff47aa8234a6225b1a7710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b342dfe3284771b56959773d0e0028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Set up BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ui2sCyiC3RK"
   },
   "source": [
    "All the required functions for fetch and work are initialised and defined here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZanimNaRD3B"
   },
   "source": [
    "1.Define a function to authenticate with the YouTube API using the OAuth 2.0 flow. This function returns a service object that can be used to make API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0mYNDInSpZw"
   },
   "source": [
    "2. Define functions for preprocessing text and predicting hate speech using the loaded BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYgdQcgnTSLu"
   },
   "source": [
    "3. Define a function to fetch live comments from a specified YouTube video using the YouTube API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yeww2BFLT1rN"
   },
   "source": [
    "4. main execution\n",
    "In the main part of the script:\n",
    "Authenticate with the YouTube API.\n",
    "Fetch live comments from a specified YouTube video.\n",
    "Save the comments to a CSV file.\n",
    "Perform hate speech detection on each comment and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TOKEN and API authentication\n",
    "def get_authenticated_service():\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
    "    credentials = flow.run_local_server(port=7587)\n",
    "    return build(API_SERVICE_NAME, API_VERSION, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocessing of fetched data to give as input to the transformers\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KL_xhiVh29M",
    "outputId": "967eafa3-9f56-43e2-e76b-5b57a0d7f13f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=422487092710-ud2upt20gb8857oc2mdq5vmsn1jake0c.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A7587%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=ejX36i84e7GhRfEMuCCiTSgbEpJib0&access_type=offline\n",
      "Fetched 100 comments so far.\n",
      "Live comments saved to live_comments.csv\n",
      "Comment: Kya yeti tak ye video pohocha sakte ho?\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Sport meğŸ˜¢\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.46\n",
      "\n",
      "Comment: ChadguruğŸ—¿ğŸ—¿ğŸ—¿ğŸ—¿ğŸ—¿ğŸ—¿\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: 2:02 \n",
      "ğŸ˜‚ğŸ˜…ğŸ˜…ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Perfect ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: â¤â¤â¤â¤ğŸ˜…ğŸ˜…ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: ğŸ¤£ğŸ¤£ helerious 8:28\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.39\n",
      "\n",
      "Comment: Carry bhaiiiiiiiiiii ke aage koi bol skta hai kya \n",
      "Munna bhai : hağŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.41\n",
      "\n",
      "Comment: Legend â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Carry Bhai â™¥ï¸\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Carry opâ¤â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: AEISA LAG RHA JAISE KITNE SAAL BAAD VIDEO AAYA HAIğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: All YT in all video\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: â¤â¤â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: This man has proved everyone that he can entertain anyone without using derogatory words\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.41\n",
      "\n",
      "Comment: what a video!!!!! absolutely crazyyyyy, LOVEDDDDD ITTTğŸ˜­ğŸ‘ŒğŸ»\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Bhut badiya ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Nice ğŸ‘\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Carry bhai opğŸ˜‚â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Next leval\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Carry looks more real  from the real character . Such a gem who never disappoints  us\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.40\n",
      "\n",
      "Comment: ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Bhai. Pata nahi kyu par kuch missing lag raha hai yaar .ğŸ¤”\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: ğŸ˜‚...\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: 1no. Superb acting\n",
      "\n",
      "Elvish jese chutiyo dikho is se kuch\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: 11:31 hilarious ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: iske baad humne mari aik aur fabğŸ¤£ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Carry Bhai ko jo legend mante hai like karo\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Motivational ki m** c***d di ğŸ˜…ğŸ˜…ğŸ˜…ğŸ˜…ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: ğŸ–¤ğŸ–¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: i started watching video at 200 thousand views and ended up at 500 thousand.\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Whattt a video ! The acting was on point and the humour ğŸ¤£ğŸ¤£ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Jaldi jaldi comments kr deta hu like milenge ğŸ˜¢ğŸ˜Š\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: the carryminati come back ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Oxygen doğŸ˜ğŸ˜â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Jaldi jaldi comments kar du like mil jayega\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Ekdin mera bhi comment Viral hoga âœ”ï¸\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Bawaaalll ğŸ˜…ğŸ˜…ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: ğŸ˜…ğŸ˜‚ğŸ˜†ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Love from Bangladesh â¤ğŸ˜Š\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: ankit bhai >>>>>>>>>>> kalankit bhai\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Carry is the best roster ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.46\n",
      "\n",
      "Comment: Carry vai josss â¤â¤â¤ \n",
      " Love from Bangladesh ğŸ’¥\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Iske viewers ko sb pata h yahi chutiya h ğŸ¤£ğŸ¤£ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Kasam se acting ki baat badsahh hoo apo toğŸ¤“\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: One 9f the best video of carry minati\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Aman saleh\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Phone me salute wali emoji nhi h, nhi to abhi comment krdeta ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.41\n",
      "\n",
      "Comment: wth did I just see? This is going to be a blockbuster, which breaks all the records.â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Challenge kro ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: jaldi jaldi comment karta hu likes ayenge\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Your videos are amazing ğŸ‰ğŸ˜¢ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Ek pal ke liye lga ki carry Ankit hi hai\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: First vuev\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: https://youtube.com/@Vkfunnyofficial204?si=dJtzv44yFbS-MxGa à¤ªà¥à¤²à¥€à¤œ à¤¸à¤¬à¤¸à¥à¤•à¥à¤°à¤¾à¤ˆà¤¬ à¤•à¤°à¥‹ ğŸ˜­\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Bhaiii maja hi aa gaya ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Comment fast\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Wahh!! Kya Accent Pakda Hai Maheshwari Sir Ka...Bas Wo Chutki masalne wla reh gyağŸ˜‚ğŸ‘\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Kya yeti bhi YouTube use karte hai ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Controversy incoming\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: 0% Comedy\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Chadguru kam asharaam jyaada lag re ho ğŸ¤£ğŸ¤£ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Carry ğŸ”¥ğŸ”¥ğŸ”¥ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: i am speechless. bro what a performace. bollywood mere l**de pe\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Sadhguru got roastedğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: OMG haha I m not Stop to my Laugh ğŸ˜‚ğŸ’¯ğŸ¤£\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: ChadguruğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Jldi jldi comment krdeta hu like milegağŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: That's today's reality, there's a huge difference in normal & social life.\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Carry played the roles more than actual people like sandeep, ankit bhai and sadhguru ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: â¤ bhai loveà¤‰\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Jai hind â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Who skip winzo promotion ğŸ˜‚ğŸ˜‚ğŸ˜‚â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.46\n",
      "\n",
      "Comment: 5:20 Sadhguruâ¤ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.40\n",
      "\n",
      "Comment: Just Looking Like A WOW ğŸ˜²\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Love you Bro â¤â¤â¤â¤â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚â¤â¤â¤â¤ğŸ˜‚ğŸ˜‚â¤ğŸ˜‚â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Sadguru dhongi aur pakhandi admi\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Hey guys Subscribe My channel â¤ï¸\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: Yar Bharat World Cup har gya kuch v dekhne me maaja nhi aara HhğŸ’”ğŸ˜­\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: East to West, carry is bestğŸ‰\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Jidi jidi comment kar Deta hu like mil jayege ğŸ˜ŠğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Yar ek hi Dil hai Carry, Kitni baar jeetoge ğŸ‰â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Great work. Grateful to God that you were born in our country\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.38\n",
      "\n",
      "Comment: Jaldi jaldi comment kardeta hu like miljayengeğŸ˜‚ğŸ˜‚ğŸ˜…\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Kya  bhai me kab youtuber ban paunga ğŸ˜¢ğŸ˜¢ğŸ˜¢ğŸ˜¢ğŸ˜¢\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n",
      "Comment: Apni video promote krne k liye mere show pe aa gaya vo bhi apni video me khud main bankeğŸ¤£ğŸ¤£ğŸ”¥\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.47\n",
      "\n",
      "Comment: Mera comment ek din jarur viral hogağŸ˜¢\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.45\n",
      "\n",
      "Comment: I want something new and i found something new ğŸ¥¹ğŸ˜ğŸ˜†ğŸ˜†maja aa gya\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: No one can beat @carryMinati ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.41\n",
      "\n",
      "Comment: beer bicep wala act bahoot funny hai carry bhai 'ğŸ˜‚ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Like for carry bhai â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: ğŸ˜‚ğŸ˜‚ carryminati as role in video is unexpected ğŸ˜‚\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Chad guru was my favorite ğŸ˜·ğŸ’€\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.43\n",
      "\n",
      "Comment: Aman saleh\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.42\n",
      "\n",
      "Comment: Carry Acting is Far Better Than Bollywood Stars Kid's â¤\n",
      "Prediction: Not hate speech\n",
      "Confidence: 0.44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sentiment analysis by the transformer to identify the hate speech comments(1) and non-hate speech comments(0)\n",
    "def predict_hate_speech(text):\n",
    "    inputs = preprocess_text(text)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1).item()\n",
    "    return prediction, probabilities[0][1].item()\n",
    "\n",
    "#Fetch call for the comments from the YouTube\n",
    "def fetch_live_comments(youtube_service, video_id, polling_interval=10, max_comments=50):\n",
    "    comments = []\n",
    "    total_comments_fetched = 0\n",
    "\n",
    "    while total_comments_fetched < max_comments:\n",
    "        response = youtube_service.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100\n",
    "        ).execute()\n",
    "\n",
    "        for item in response.get(\"items\", []):\n",
    "            comment_text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(comment_text)\n",
    "\n",
    "        total_comments_fetched += len(response[\"items\"])\n",
    "        print(f\"Fetched {total_comments_fetched} comments so far.\")\n",
    "\n",
    "        time.sleep(polling_interval)\n",
    "\n",
    "    return comments\n",
    "#4\n",
    "if __name__ == \"__main__\":\n",
    "    youtube_service = get_authenticated_service()\n",
    "\n",
    "    video_id = \"P8P_S1Fjl_Q\"  # Replace with the actual video ID\n",
    "    live_comments = fetch_live_comments(youtube_service, video_id)\n",
    "\n",
    "    csv_filename = \"live_comments.csv\"\n",
    "    with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Comment\"])\n",
    "        for comment in live_comments:\n",
    "            writer.writerow([comment])\n",
    "\n",
    "    print(f\"Live comments saved to {csv_filename}\")\n",
    "\n",
    "    # Perform hate speech detection on live comments\n",
    "    for comment in live_comments:\n",
    "        prediction, confidence = predict_hate_speech(comment)\n",
    "        print(f\"Comment: {comment}\")\n",
    "        print(f\"Prediction: {'Hate speech' if prediction == 1 else 'Not hate speech'}\")\n",
    "        print(f\"Confidence: {confidence:.2f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
